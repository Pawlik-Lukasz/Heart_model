{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtqUXVi6XkYd8hJ5lQwTBE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pawlik-Lukasz/Heart_model/blob/main/Heart_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## My dataset encompasses medical specifications of patients, including cholesterol levels, blood pressure, and types of chest pain, along with demographic information such as age and gender.\n",
        "* ## Initially, I developed a basic model using decision tree analysis.\n",
        "* ## Upon comparison, I observed that entropy yielded superior results.\n",
        "* ## Subsequently, I pruned the decision tree, employing entropy as the criterion.\n",
        "* ## I selected the optimal parameters for the forest and constructed a random forest model based on them.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xzS9RoLdX20I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kAPz8y9YII13"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with decision tree algorithm\n",
        "df = pd.read_csv('heart.csv')\n",
        "X = df[['cp', 'sex', 'age', 'trestbps', 'chol',\n",
        "'thalach', 'fbs', 'restecg', 'exang', 'oldpeak', 'slope', 'ca', 'thal']].values\n",
        "y = df['target'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=22)\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "56jiMNBTIPuv",
        "outputId": "e586ca7b-198e-44c2-e3b9-2cda6a6cedb7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'heart.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-33cd01b6b278>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model z wykorzystaniem algorytmu drzewa decyzyjnego\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'heart.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m X = df[['cp', 'sex', 'age', 'trestbps', 'chol',\n\u001b[1;32m      4\u001b[0m 'thalach', 'fbs', 'restecg', 'exang', 'oldpeak', 'slope', 'ca', 'thal']].values\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'heart.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model fine-tuned using Gini impurity and entropy criteria\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "for criterion in ['gini', 'entropy']:\n",
        "    print(\"Decision Tree - {}\".format(criterion))\n",
        "    accuracy = []\n",
        "    precision = []\n",
        "    recall = []\n",
        "    f1 = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        dt = DecisionTreeClassifier(criterion=criterion, random_state=42)\n",
        "        dt.fit(X_train, y_train)\n",
        "        y_pred = dt.predict(X_test)\n",
        "\n",
        "        accuracy.append(accuracy_score(y_test, y_pred))\n",
        "        precision.append(precision_score(y_test, y_pred))\n",
        "        recall.append(recall_score(y_test, y_pred))\n",
        "        f1.append(f1_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "    print(\"accuracy:\", np.mean(accuracy))\n",
        "    print(\"precision:\", np.mean(precision))\n",
        "    print(\"recall:\", np.mean(recall))\n",
        "    print(\"f1:\", np.mean(f1), '\\n')\n",
        "\n",
        "# It is evident that the model using entropy criterion performed better, so we will\n",
        "# use entropy as our later criterion"
      ],
      "metadata": {
        "id": "FrlojoFgJBT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prune the decision tree and evaluate it, select the best model, and justify the choice\n",
        "param_grid = {\n",
        " 'max_depth': [5, 10, 15, 20],\n",
        " 'min_samples_leaf': [1, 2, 3],\n",
        " 'max_leaf_nodes': [10, 20, 35, 50]}\n",
        "# I'm using entropy criterion because from the previous point I learned that\n",
        "# such a model will perform better in our case\n",
        "dt = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "gs = GridSearchCV(dt, param_grid, scoring='f1', cv=5)\n",
        "gs.fit(X, y)\n",
        "print(\"best params:\", gs.best_params_)\n",
        "print(\"best score:\", gs.best_score_)\n",
        "\n",
        "# With these settings, the most optimal decision tree has a height of 5,\n",
        "# the minimum number of leaf samples is 2\n",
        "# and the maximum number of leaf nodes in the tree is 10"
      ],
      "metadata": {
        "id": "TVu5UdBJJDAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of model made in matplotlib\n",
        "plt.figure(figsize=(15, 10))\n",
        "plot_tree(gs.best_estimator_, filled=True, feature_names=['cp', 'sex', 'age', 'trestbps', 'chol',\n",
        "'thalach', 'fbs', 'restecg', 'exang', 'oldpeak', 'slope', 'ca', 'thal'], class_names=['0', '1'], rounded=True)"
      ],
      "metadata": {
        "id": "YHw3g27zxpsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model with random forest algorithm\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=101)\n",
        "rf_model = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "23gsLHMV6gLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model using GridSearchCV and visualize the estimators\n",
        "n_estimators = list(range(1, 101))\n",
        "# Parameter grid to search through\n",
        "param_grid = {'n_estimators': n_estimators}\n",
        "\n",
        "gs = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation mean accuracy scores\n",
        "scores = gs.cv_results_['mean_test_score']\n",
        "\n",
        "# Estimators visualization\n",
        "plt.plot(n_estimators, scores)\n",
        "plt.xlabel(\"Number of Estimators\")\n",
        "plt.ylabel(\"Mean Accuracy\")\n",
        "plt.title(\"Impact of Number of Estimators on Model Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# As we can see, our model levels off around 20 trees, so we can assume that\n",
        "# the appropriate number of estimators is 20"
      ],
      "metadata": {
        "id": "3lWzk0WfXeP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select relevant features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=101)\n",
        "rf = RandomForestClassifier(n_estimators=20, random_state=111)\n",
        "rf.fit(X_train, y_train)\n",
        "feature_importances = pd.Series(rf.feature_importances_,\n",
        "index=['cp', 'sex', 'age', 'trestbps', 'chol',\n",
        "'thalach', 'fbs', 'restecg', 'exang', 'oldpeak', 'slope', 'ca', 'thal']).sort_values(ascending=False)\n",
        "\n",
        "# Assuming significant features are those above the threshold of 0.05\n",
        "significant_features = feature_importances[feature_importances > 0.05].index.tolist()\n",
        "print(f\"Significant features:\\n {significant_features}\")\n",
        "\n",
        "# Feature importance plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "feature_importances.plot(kind='bar')\n",
        "plt.title(\"Feature Importance in Random Forest Model\")\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Oou24EVRRsEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LeKJXCoYXt3F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}